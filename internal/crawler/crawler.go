package crawler

import (
	"bytes"
	"fmt"
	"io"
	"net/http"
	"regexp"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
)

type Torrent struct {
	Name       string
	Category   string
	Size       string
	Seeds      int
	Leeches    int
	URL        string
	ImageURL   string
	CSFDRating string // hodnocen√≠ z n√°zvu, nap≈ô. "77%"
	CSFDURL    string // p≈ô√≠m√Ω odkaz na ƒåSFD (voliteln√©, pomal√© stahov√°n√≠)
}

type CrawlResult struct {
	PageNum  int
	Torrents []Torrent
	Error    error
}

type Config struct {
	Workers   int
	BaseURL   string
	UserAgent string
	Timeout   time.Duration
}

type Crawler struct {
	client    *http.Client
	config    Config
	csfdRegex *regexp.Regexp
}

func NewCrawler(config Config) *Crawler {
	if config.BaseURL == "" {
		config.BaseURL = "https://sktorrent.eu/torrent/torrents_v2.php?active=0&order=data&by=DESC&zaner=&jazyk=&page=0"
	}
	if config.UserAgent == "" {
		config.UserAgent = "Mozilla/5.0 (compatible; SkTorrent-Crawler/1.0)"
	}
	if config.Timeout == 0 {
		config.Timeout = 30 * time.Second
	}
	if config.Workers <= 0 {
		config.Workers = 3
	}

	// Regex pro parsov√°n√≠ ƒåSFD hodnocen√≠ z n√°zvu
	csfdRegex := regexp.MustCompile(`=\s*CSFD\s*(\d+)%`)

	return &Crawler{
		client: &http.Client{
			Timeout: config.Timeout,
		},
		config:    config,
		csfdRegex: csfdRegex,
	}
}

func (c *Crawler) Crawl(from int, to int) {
	// Vytvo≈ôen√≠ kan√°l≈Ø pro paraleln√≠ zpracov√°n√≠
	jobs := make(chan int, to-from+1)
	results := make(chan CrawlResult, to-from+1)

	// Spu≈°tƒõn√≠ worker≈Ø
	var wg sync.WaitGroup
	for i := 0; i < c.config.Workers; i++ {
		wg.Add(1)
		go c.worker(jobs, results, &wg)
	}

	// Odesl√°n√≠ √∫kol≈Ø do kan√°lu
	go func() {
		for pageNum := from; pageNum <= to; pageNum++ {
			jobs <- pageNum
		}
		close(jobs)
	}()

	// ƒåek√°n√≠ na dokonƒçen√≠ v≈°ech worker≈Ø
	go func() {
		wg.Wait()
		close(results)
	}()

	// Sb√≠r√°n√≠ a zobrazen√≠ v√Ωsledk≈Ø
	c.processResults(results)
}

func (c *Crawler) worker(jobs <-chan int, results chan<- CrawlResult, wg *sync.WaitGroup) {
	defer wg.Done()

	for pageNum := range jobs {
		fmt.Printf("Worker processing page %d...\n", pageNum)
		torrents, err := c.crawlPage(pageNum)
		results <- CrawlResult{
			PageNum:  pageNum,
			Torrents: torrents,
			Error:    err,
		}
	}
}

func (c *Crawler) crawlPage(pageNum int) ([]Torrent, error) {
	url := fmt.Sprintf("%s&page=%d", c.config.BaseURL, pageNum)

	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		return nil, fmt.Errorf("creating request: %w", err)
	}
	req.Header.Set("User-Agent", c.config.UserAgent)

	response, err := c.client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("fetching page %d: %w", pageNum, err)
	}
	defer response.Body.Close()

	if response.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("page %d returned status %d", pageNum, response.StatusCode)
	}

	body, err := io.ReadAll(response.Body)
	if err != nil {
		return nil, fmt.Errorf("reading response body: %w", err)
	}

	// Parsov√°n√≠ torrent≈Ø p≈ô√≠mo z pamƒõti
	doc, err := goquery.NewDocumentFromReader(bytes.NewReader(body))
	if err != nil {
		return nil, fmt.Errorf("parsing HTML: %w", err)
	}

	torrents := c.parseTorrents(doc)
	return torrents, nil
}

func (c *Crawler) parseTorrents(doc *goquery.Document) []Torrent {
	var torrents []Torrent

	doc.Find("TD.lista").Each(func(i int, s *goquery.Selection) {
		// Zkontrolovat, zda obsahuje odkaz na details.php
		detailsLink := s.Find("A[href*='details.php']")
		if detailsLink.Length() == 0 {
			return
		}

		var torrent Torrent

		// N√°zev torrentu
		torrent.Name = strings.TrimSpace(detailsLink.Text())
		if torrent.Name == "" {
			return
		}

		// URL
		if href, exists := detailsLink.Attr("href"); exists {
			torrent.URL = "https://sktorrent.eu/torrent/" + href
		}

		// ƒåSFD hodnocen√≠ z n√°zvu
		torrent.CSFDRating = c.parseCSFDRating(torrent.Name)

		// Kategorie
		categoryLink := s.Find("a[href*='torrents_v2.php?category=']")
		if categoryLink.Length() > 0 {
			torrent.Category = strings.TrimSpace(categoryLink.Text())
		}

		// URL obr√°zku
		imgElement := s.Find("img.lozad")
		if imgElement.Length() > 0 {
			if dataSrc, exists := imgElement.Attr("data-src"); exists {
				torrent.ImageURL = dataSrc
			}
		}

		// Velikost, seeders, leechers
		c.parseMetadata(s, &torrent)

		// V≈ædy st√°hnout p≈ô√≠m√Ω ƒåSFD odkaz z detail str√°nky (pokud m√° ƒåSFD hodnocen√≠)
		if torrent.CSFDRating != "" {
			torrent.CSFDURL = c.fetchCSFDURL(torrent.URL)
		}

		torrents = append(torrents, torrent)
	})

	return torrents
}

func (c *Crawler) parseCSFDRating(name string) string {
	matches := c.csfdRegex.FindStringSubmatch(name)
	if len(matches) >= 2 {
		return matches[1] + "%"
	}
	return ""
}

func (c *Crawler) fetchCSFDURL(detailURL string) string {
	if detailURL == "" {
		return ""
	}

	req, err := http.NewRequest("GET", detailURL, nil)
	if err != nil {
		return ""
	}
	req.Header.Set("User-Agent", c.config.UserAgent)

	resp, err := c.client.Do(req)
	if err != nil {
		return ""
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return ""
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return ""
	}

	doc, err := goquery.NewDocumentFromReader(bytes.NewReader(body))
	if err != nil {
		return ""
	}

	// Hledat ƒåSFD odkaz pomoc√≠ r≈Øzn√Ωch selektor≈Ø
	csfdSelectors := []string{
		`a[itemprop="sameAs"][href*="csfd.cz"]`,
		`a[href*="csfd.cz/film/"]`,
		`a[href*="csfd.sk/film/"]`,
	}

	for _, selector := range csfdSelectors {
		link := doc.Find(selector).First()
		if link.Length() > 0 {
			if href, exists := link.Attr("href"); exists {
				return href
			}
		}
	}

	return ""
}

func (c *Crawler) parseMetadata(s *goquery.Selection, torrent *Torrent) {
	s.Find("*").Each(func(j int, textNode *goquery.Selection) {
		text := textNode.Text()
		if !strings.Contains(text, "Velkost") {
			return
		}

		lines := strings.Split(text, "\n")
		for _, line := range lines {
			line = strings.TrimSpace(line)

			if strings.HasPrefix(line, "Velkost") {
				torrent.Size = strings.TrimSpace(strings.Replace(line, "Velkost", "", 1))
			} else if strings.HasPrefix(line, "Odosielaju") {
				seedText := strings.TrimSpace(strings.Replace(line, "Odosielaju :", "", 1))
				fmt.Sscanf(seedText, "%d", &torrent.Seeds)
			} else if strings.HasPrefix(line, "Stahuju") {
				leechText := strings.TrimSpace(strings.Replace(line, "Stahuju :", "", 1))
				fmt.Sscanf(leechText, "%d", &torrent.Leeches)
			}
		}
	})
}

func (c *Crawler) processResults(results <-chan CrawlResult) {
	resultMap := make(map[int]CrawlResult)

	// Sb√≠r√°n√≠ v≈°ech v√Ωsledk≈Ø
	for result := range results {
		resultMap[result.PageNum] = result
	}

	// Zobrazen√≠ v√Ωsledk≈Ø v po≈ôad√≠
	totalTorrents := 0
	for pageNum := range resultMap {
		result := resultMap[pageNum]

		if result.Error != nil {
			fmt.Printf("‚ùå CHYBA na str√°nce %d: %v\n", result.PageNum, result.Error)
			continue
		}

		fmt.Printf("\nüî• STR√ÅNKA %d - NALEZENO %d TORRENT≈Æ üî•\n", result.PageNum, len(result.Torrents))

		for j, torrent := range result.Torrents {
			fmt.Printf("[%d] üì∫ %s\n", j+1, torrent.Name)
			fmt.Printf("    üè∑Ô∏è  Kategorie: %s\n", torrent.Category)
			fmt.Printf("    üì¶ Velikost: %s\n", torrent.Size)
			fmt.Printf("    üå± Seeders: %d | ü©∏ Leechers: %d\n", torrent.Seeds, torrent.Leeches)
			if torrent.CSFDRating != "" {
				fmt.Printf("    ‚≠ê ƒåSFD: %s\n", torrent.CSFDRating)
			}
			if torrent.CSFDURL != "" {
				fmt.Printf("    üé¨ ƒåSFD URL: %s\n", torrent.CSFDURL)
			}
			if torrent.ImageURL != "" {
				fmt.Printf("    üñºÔ∏è  Obr√°zek: %s\n", torrent.ImageURL)
			}
			fmt.Printf("    üîó URL: %s\n", torrent.URL)
			fmt.Println("    " + strings.Repeat("‚îÄ", 60))
		}

		totalTorrents += len(result.Torrents)
		fmt.Printf("‚úÖ KONEC STR√ÅNKY %d\n", result.PageNum)
	}

	fmt.Printf("\nüéâ CRAWLING DOKONƒåEN! üéâ\n")
	fmt.Printf("üìä Celkov√Ω poƒçet torrent≈Ø: %d\n", totalTorrents)
	fmt.Printf("‚öôÔ∏è  Pou≈æito worker≈Ø: %d\n", c.config.Workers)
}
